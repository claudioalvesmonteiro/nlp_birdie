{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CPIrc0PsobsU"
   },
   "source": [
    "# Teste Técnico Birdie\n",
    "\n",
    "@claudioalvesmonteiro\n",
    "Junho, 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EIxeKBzmoBIG"
   },
   "source": [
    "\n",
    "### Explorar\n",
    "1. extração de aspectos: palavras dentro de um texto que codificam uma característica de seu funcionamento, estrutura, ou do processo de compra (entrega, SAC, consertos e problemas)\n",
    "2. o quê está sendo falado nos canais de venda de seus produtos\n",
    "3. Encontrar uma maneira de extrair estes aspectos;\n",
    "4. Explorar essas informações para gerar insights (por exemplo, quais aspectos estão mais relacionados com reviews positivos?);\n",
    "5. Opcionalmente, criar gráficos e propostas de visualizações para suas observações\n",
    "6. NLP, named entity recognition, syntax pattern matching, feature extraction, topic representation, word embedding, sentence embedding\n",
    "\n",
    "### Desenvolver\n",
    "\n",
    "0. Criar variável comentario_clean\n",
    "1. Contagem de palavras total para explorar aspectos mais falados;\n",
    "2. Identificar os aspectos em cada comentário e salvar em variável;\n",
    "3. Criar variável comentário_positivo (3 estrelas pra cima) e comentario_negativo (2 estrelas pra baixo)\n",
    "4. Capturar bag of words count (+ e -) para cada aspecto identificado;\n",
    "5. Visualização wordcloud e wordcount para cada aspecto identificado; \n",
    "6. Volume de visualização por semana/horariododia e mes/semana\n",
    "7. Tipo de geladeira (breadcrumb) mais bem avaliados e mal avaliados por marca (brand, > 5%)\n",
    "8. Comparar caracteristicas das mais bem e mal avaliados 'specs'\n",
    "\n",
    "\n",
    "9. explorar tendencia temporal das avaliações dos produtos (% de avaliacoes positivas), line-plot and thick bar, por aspecto do produto\n",
    "10. indicador mensal de \"satisfação do cliente\", apresentando o que foi bom e ruim naquele mês \n",
    "11. relação com retailer (distribuidora)\n",
    "12. similaridade entre textos (?)\n",
    "13. modelagem para ver o que influencia ter uma boa avaliação (?)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ASuSYAsDoyib"
   },
   "source": [
    "# Pré-processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com os objetivos definidos, o primeiro passo é pré-processar os comentários e colocar as palavras em caixa baixa, remover números, remover stopwords (conectivos) e aplicar o algoritmo lemmantization. Com isso padronizamos nosso texto para fazer uma extração de características mais eficiente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UYjM8t9spk0h"
   },
   "outputs": [],
   "source": [
    "# importar pacotes\n",
    "import pandas as pd\n",
    "import nltk\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 271
    },
    "colab_type": "code",
    "id": "NzQJhgBvpeCz",
    "outputId": "a6edde26-efe8-4e39-e8a3-d6c44bb0e0c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69.31 % de casos duplicados na base\n"
     ]
    }
   ],
   "source": [
    "# importar dataset\n",
    "data = pd.read_csv('data/tech_test.tsv')\n",
    "\n",
    "# porcentagem de casos duplicados\n",
    "print(round(sum(data.duplicated('review_id'))/len(data)*100, 2),'% de casos duplicados na base')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observando a estrutura dos dados pude observar que haviam reviews exatamente iguais mas apenas com momento de coleta diferentes, então acredito que isso seja resultado de algum processo na coleta dos dados. Como isso poderia gerar um viés na análise já que vou executar a contagem de termos, decidi por excluir reviews com ID duplicado. Num projeto 'real', eu discutiria bem isso com a equipe responsável pela base de dados para esclarecer melhor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remover reviews duplicadas\n",
    "data = data.drop_duplicates('review_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "uUY90yU6qGf7",
    "outputId": "53a1f91c-0a96-4736-8169-c6c2886180ca"
   },
   "outputs": [],
   "source": [
    "def cleanTextToken(text, tokenization = True):\n",
    "    ''' funcao para extrair palavras e \n",
    "        padronizar texto.\n",
    "    '''\n",
    "    # transforma em caixa baixa\n",
    "    text = text.lower()\n",
    "    # remove numeros\n",
    "    text = ''.join([i for i in text if not i.isdigit()]) \n",
    "    # remove pontuacao\n",
    "    from nltk.tokenize import RegexpTokenizer\n",
    "    tokenizer = RegexpTokenizer(r'\\w+') # preserva palavras e alfanumericos\n",
    "    text = tokenizer.tokenize(text)\n",
    "    # remove stopwords\n",
    "    import nltk\n",
    "    from nltk.corpus import stopwords\n",
    "    stop = set(stopwords.words('english'))\n",
    "    text = [w for w in text if not w in stop] \n",
    "    # lemmatization\n",
    "    from nltk.stem import WordNetLemmatizer \n",
    "    lemmatizer = WordNetLemmatizer() \n",
    "    text = [lemmatizer.lemmatize(word) for word in text]\n",
    "    # retorna tokens limpos\n",
    "    return(text)\n",
    "\n",
    "# gerar variavel com comentario 'limpo'\n",
    "data['review_body_token'] = [cleanTextToken(text) for text in data['review_body']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora é possível fazer uma contagem dos termos mais frequentes e testar se é possível extrair aspectos a partir disso. Com um modelo pré-treinado do pacote nltk consegui extrair a categoria da palavra (substantivo, adjetivo, pronome, etc.) e assim afunilar a busca por aspectos relevantes dos produtos em substantivos e posteriormente relacionar esses aspectos com a avaliação e com outras variáveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordCount(txt_list):\n",
    "    ''' contar frequencia de palavras em lista e\n",
    "        salvar em dataframe\n",
    "    '''\n",
    "    # dicionario com informacoes\n",
    "    wordfreq = {'word':[],'freq':[]}\n",
    "    # iteracao na lista\n",
    "    for word in txt_list:\n",
    "        if word not in wordfreq['word']:\n",
    "            wordfreq['word'].append(word)                   # salvar palavra\n",
    "            wordfreq['freq'].append(txt_list.count(word))   # calcular frequencia na lista\n",
    "    # transformar em dataframe \n",
    "    count = pd.DataFrame(wordfreq)\n",
    "    # sort_values in df\n",
    "    count.sort_values('freq', inplace=True, ascending=False)\n",
    "    # return df\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combinar todas as palavras de todos os comentarios\n",
    "all_tokens = []\n",
    "for comment in data['review_body_token']:\n",
    "    for word in comment:\n",
    "        all_tokens.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contabilizar\n",
    "all_count = wordCount(all_tokens[0:100000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcao para identificar classe gramatical de palavras \n",
    "def nltkPerceptronClass(column):\n",
    "    new_column =[]\n",
    "    for word in column:\n",
    "        new_column.append(nltk.pos_tag([word])[0][1])\n",
    "    return new_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# executar identifc de classe gramatical\n",
    "all_count['category'] = nltkPerceptronClass(all_count['word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>freq</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>fridge</td>\n",
       "      <td>2473</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>door</td>\n",
       "      <td>1823</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>ice</td>\n",
       "      <td>1790</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>refrigerator</td>\n",
       "      <td>1505</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>part</td>\n",
       "      <td>1420</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>446</td>\n",
       "      <td>temperature</td>\n",
       "      <td>207</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>557</td>\n",
       "      <td>stainless</td>\n",
       "      <td>207</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>303</td>\n",
       "      <td>loud</td>\n",
       "      <td>206</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>527</td>\n",
       "      <td>samsung</td>\n",
       "      <td>204</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>473</td>\n",
       "      <td>noise</td>\n",
       "      <td>201</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             word  freq category\n",
       "42         fridge  2473       NN\n",
       "28           door  1823       NN\n",
       "16            ice  1790       NN\n",
       "102  refrigerator  1505       NN\n",
       "47           part  1420       NN\n",
       "..            ...   ...      ...\n",
       "446   temperature   207       NN\n",
       "557     stainless   207       NN\n",
       "303          loud   206       NN\n",
       "527       samsung   204       NN\n",
       "473         noise   201       NN\n",
       "\n",
       "[61 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualizar substantivos com mais de 0,1% de representacao na base\n",
    "all_count[(all_count['category'] == 'NN') & (all_count['freq'] > (sum(all_count['freq'])*0.002))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com base nessa análise exploratória é possível levantar palavras de relevância nos reviews, que podem servir como aspetos a serem analisados e cruzados com outras variáveis para compreender com mais detalhes as avaliações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['fridge'\n",
    "            'door'\n",
    "            'ice'\n",
    "            'refrigerator'\n",
    "            'freezer'\n",
    "            'promotion'\n",
    "            'water'\n",
    "            'space'\n",
    "            'shelf'\n",
    "            'side'\n",
    "            'month'\n",
    "            'room'\n",
    "            'dispenser',\n",
    "            'time',\n",
    "            'size',\n",
    "            'problem',\n",
    "            'price',\n",
    "            'light',\n",
    "            'temperature',\n",
    "            'noise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-12-321eeda4402d>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-12-321eeda4402d>\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    \u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "# criar variavel de features presentes na review\n",
    "features_var = []\n",
    "for row in data['review_body_token']:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# para cada feature sera possivel visualizar wordcloud/wordcount X avaliacoes positivas/avaliacoes negativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "teste_birdie.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
